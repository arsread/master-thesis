%%==================================================
%% abstract.tex for SJTU Master Thesis
%% based on CASthesis
%% modified by wei.jianwen@gmail.com
%% version: 0.3a
%% Encoding: UTF-8
%% last update: Dec 5th, 2010
%%==================================================

\begin{abstract}

近年来，计算机硬件技术发展日新月异，多核、分布式等领域也产生了许多新技术，使一些大规模处理的任务效率有效地得到提高。因此并行化编程也称为了热门话题，相关地技术被广泛地应用于其他领域。

程序分析就是其中之一。传统的程序分析领域里有许多任务的复杂度太高，会耗费许多时间，例如符号执行、指针分析等等，这些技术的算法复杂度决定了分析者只能在效率和精度上做权衡。而并行化的引入在一定程度上放宽了效率的限制。研究表明，程序分析中，有很多方法和任务并没有需要返回值，并且这些方法之间没有严格的时序关系，这表明这些方法是可以被并行的。

但并行化又带来了相应的问题。在一些细颗粒度的任务中，由于并行处理需要各线程间进行通信，这种通信带来的开销在并行频繁的时候会非常大，有时甚至要高于串行执行本身的开销，使得最终的效率不升反降，并行化的初衷就失去了意义。

为了解决这一问题，以Deferred Method为代表的一系列框架通过使用基于缓存的处理机制来执行并行化。每个分析程序的线程都维持着一个缓存，程序使用并行方法时，并没有马上交付给相应的处理线程进行处理，而是先在缓存里把调用信息储存起来，等到缓存填满的时候，再交给处理线程进行处理。与其他类似框架相比，Deferred Method框架具有多线程，支持结果合并等特点。

本文即是在Deferred Method框架的基础上做了优化，这些优化包括：加入检查点，允许一部分任务集之间有粗颗粒度的时序逻辑；新增了影子线程，允许多线程程序中每个线程的缓存都能以顺序进行执行；对锁和synchronized关键字的机制做优化，避免因为线程阻塞而使得缓存中的部分任务长时间得不到执行；支持带有返回值的方法的并行化，增强了该框架的适用范围。

本文的创新点主要有两个方面：

\begin{enumerate}
	\item 高层面的接口。用户不需要关心这个框架的底层实现，而只需要简单地了解这套接口的使用方法，就可以用很少的代码完成并行方法的设置。
	\item 字节码动态生成。整个框架的行为对用户是透明的，字节码分析、方法行为的重写等过程都是由框架自动根据用户的需要完成的。
\end{enumerate}

通过使用改进后的方法,Deferred Method框架的功能得到了完善，开发者可以使用改进后的框架完成具有更多功能的并行程序，包括一定时序逻辑和返回值等，另外通过同步优化，该框架在效率上也有提高。相关的实验也表明，这些功能在表现上是符合预期的。在检查点的使用上，如果使用频度得当，程序只会引入5\%$\sim$12\%左右的开销，但如果使用过于频繁，开销将变为原来的2倍；在影子线程上，由于机器和测试用例的限制，开销会比自适应的策略多16\%$\sim$20\%的开销；在锁优化上，优化后的程序比原来的并行能快10\%$\sim$53\%.总而言之，本文提出的优化为并行程序分析的开发者带来了更多的选择，提高了并行程序分析的适用范围。

  \keywords{\large 并行计算 \quad 程序分析 \quad 代码生成}
\end{abstract}

\begin{englishabstract}

In recent years, with the development of computer hardware technique, some new systems has been invented to help high-performance processing, such as multi-core systems and distributed systems. Those technique help increase the efficiency of some large scale task, which make parallel programing a hot topic. Related usage of it has been applied to other fields.

Program analysis is among such fields. Traditionally, there exist some tasks of program analysis which has a high complexity. These tasks, which includes symbolic execution, point-to analysis, will consuming large amount of time for processing the analyzing. In these cases, developers was forced to make a trade-off between accuracy and efficiency.

With the assistance of parallelization, this problem can somehow be reduced by executing the tasks simultaneously. It is found that many of the tasks in program analysis do not require returning a value as well as some executing order, which gives the possibility to parallelize them.

However other trade-off are introduced in such parallelization. Particularly, in some fine-grained tasks, overhead keeps high while inter-thread communication happens frequently. In extreme cases, the overhead will overwhelm the advantage of parallelization, which make it lose its motivation.

Some frameworks aim to solve this problem. Deferred Method is representative by using a mechanism of buffering. Instead of processing such methods directly, it will first deposit the information of the method invocation to a thread-local buffer. Once the buffer is full, it will be handed it to the the processor which consists of a set of threads. Comparing to other similar frameworks, Deferred Method supports multi-threads, result aggregation and so on.

In this dissertation, the implementation and optimization was performed based on the Deferred Method framework. The work contains CheckPoint which allows some coarser-grained task sets to execute in order, Shadow Thread which allows buffers produced by the same thread to be execute in order, an optimization of the synchronization in Java to help process the buffer quickly, and a implementation of methods which have return values.

The insights of this work include:

\begin{enumerate}
	\item High-level API. Programmers needn't care about the low-level implementation of this framework. They just have to know the interface of this framework and features, which can help them complete the configuration with a little amount of code.
	\item Dynamic code generation. The manners of the whole framework is transparent to the user. Bytecode parsing and method rewriting are performed by the framework automatically with the configuration written by the user.
\end{enumerate}

The features of Deferred Method become more abundant by such optimization and development. Programmers can use the modified framework to complete tasks with more various manners, such as certain time order and return values. On the other hand the synchronization optimization help increase the efficiency of the framework. Experiments on such works proved that they matched the expectation. By using the CheckPoint properly, the program will introduce the overhead of just 5\% to 12\% while twice if it is used too frequently. The Shadow Thread strategy will introduce the overhead of 16\% to 20\% due to the limitation of both the machine and the program. Synchronization optimization can retrieve a speedup of 10\% to 53\%. In conclusion, such implementation and optimization bring more choices for programmers who develop parallel programs, hence the suitable range of parallel program analysis is widen.

  \englishkeywords{\large Parallelization, Program Analysis, Code Generation}
\end{englishabstract}
